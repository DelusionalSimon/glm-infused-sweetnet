{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b80efd",
   "metadata": {},
   "source": [
    "# Infusion Evaluation System\n",
    "\n",
    "Used to Evaluate the performance of Infused, vs noninfused models over several training runs to compare different metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d390a",
   "metadata": {},
   "source": [
    "### ||RUN ON RESTART||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "719ba33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "\n",
    "from utils import build_multilabel_dataset, multilabel_split, prep_infused_sweetnet\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from glycowork.ml.processing import split_data_to_train\n",
    "from glycowork.ml import model_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ab54e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from: glm_embeddings_1.pkl\n",
      "Embeddings loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings\n",
    "\n",
    "pickle_file_path = 'glm_embeddings_1.pkl'\n",
    "\n",
    "# --- Load the Pickle File ---\n",
    "if os.path.exists(pickle_file_path):\n",
    "    print(f\"Loading embeddings from: {pickle_file_path}\")\n",
    "    try:\n",
    "        # Open the file in binary read mode ('rb')\n",
    "        with open(pickle_file_path, 'rb') as file_handle:\n",
    "            # Load the object(s) from the pickle file\n",
    "            glm_embeddings = pickle.load(file_handle)\n",
    "\n",
    "        print(\"Embeddings loaded successfully!\")        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the pickle file: {e}\")\n",
    "else:\n",
    "    print(f\"Error: File not found at '{pickle_file_path}'. Please check the filename and path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433df162",
   "metadata": {},
   "source": [
    "## Evaluation Loop\n",
    "Change parameters here for each trial run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad01d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 unique individual classes/labels.\n",
      "Number of unique glycans left after filtering rare classes (size >= 6): 1458/1648\n",
      "Number of unique labels left after filtering: 18\n"
     ]
    }
   ],
   "source": [
    "# Load part of dataset to train the model on\n",
    "\n",
    "glycans, labels, label_names = build_multilabel_dataset(glycan_dataset='df_disease', \n",
    "                                                        glycan_class='disease_association', \n",
    "                                                        min_class_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f4a46f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete!\n",
      "Train set size: 1020\n",
      "Validation set size: 219\n",
      "Test set size: 219\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train_glycans, val_glycans, test_glycans, \\\n",
    "    train_labels, val_labels, test_labels = multilabel_split(glycans, labels, train_size=0.7, \n",
    "                                                             random_state=42)\n",
    "\n",
    "# Load into dataloders for training and validation\n",
    "glycan_loaders = split_data_to_train(\n",
    "    glycan_list_train = train_glycans, glycan_list_val = val_glycans, labels_train = train_labels, labels_val = val_labels,\n",
    "    batch_size = 128,  # 32 or 128 seem to work well on this system\n",
    "    drop_last = False,\n",
    "    augment_prob = 0.0,  # Adjust if you want augmentation for training\n",
    "    generalization_prob = 0.2  # Adjust if you want generalization for training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca0a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SweetNet model instantiated with lib_size=2565, num_classes=18, hidden_dim=320.\n",
      "Handling 'external' initialization method.\n",
      "SweetNet item_embedding layer set to trainable: True.\n",
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 3.7704 LRAP: 0.0020 NDCG: 0.1450\n",
      "val Loss: 3.8337 LRAP: 0.0000 NDCG: -0.1150\n",
      "Validation loss decreased (0.000000 --> 3.833693).  Saving model ...\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 3.6634 LRAP: 0.0059 NDCG: 0.2769\n",
      "val Loss: 3.7367 LRAP: 0.0228 NDCG: 0.5497\n",
      "Validation loss decreased (3.833693 --> 3.736732).  Saving model ...\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 3.5717 LRAP: 0.0069 NDCG: 0.3490\n",
      "val Loss: 3.6126 LRAP: 0.0228 NDCG: 0.5497\n",
      "Validation loss decreased (3.736732 --> 3.612585).  Saving model ...\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 3.4672 LRAP: 0.0157 NDCG: 0.4563\n",
      "val Loss: 3.6224 LRAP: 0.0228 NDCG: 0.5402\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 3.2888 LRAP: 0.0176 NDCG: 0.5166\n",
      "val Loss: 3.3311 LRAP: 0.0228 NDCG: 0.5546\n",
      "Validation loss decreased (3.612585 --> 3.331142).  Saving model ...\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 3.1982 LRAP: 0.0471 NDCG: 0.5286\n",
      "val Loss: 3.4121 LRAP: 0.0228 NDCG: 0.5554\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 2.9894 LRAP: 0.0412 NDCG: 0.5286\n",
      "val Loss: 2.9615 LRAP: 0.0639 NDCG: 0.5131\n",
      "Validation loss decreased (3.331142 --> 2.961516).  Saving model ...\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 2.8252 LRAP: 0.0657 NDCG: 0.5273\n",
      "val Loss: 2.7824 LRAP: 0.0639 NDCG: 0.4853\n",
      "Validation loss decreased (2.961516 --> 2.782399).  Saving model ...\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 2.5920 LRAP: 0.1020 NDCG: 0.5553\n",
      "val Loss: 2.8299 LRAP: 0.1689 NDCG: 0.5392\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 2.3160 LRAP: 0.1922 NDCG: 0.5765\n",
      "val Loss: 2.4982 LRAP: 0.4977 NDCG: 0.6193\n",
      "Validation loss decreased (2.782399 --> 2.498180).  Saving model ...\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 2.0880 LRAP: 0.3196 NDCG: 0.6128\n",
      "val Loss: 2.0829 LRAP: 0.7123 NDCG: 0.6978\n",
      "Validation loss decreased (2.498180 --> 2.082898).  Saving model ...\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 1.8921 LRAP: 0.4216 NDCG: 0.6407\n",
      "val Loss: 2.3371 LRAP: 0.6621 NDCG: 0.6763\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 1.8299 LRAP: 0.4961 NDCG: 0.6562\n",
      "val Loss: 2.0958 LRAP: 0.7123 NDCG: 0.7004\n",
      "EarlyStopping counter: 2 out of 50\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 1.7653 LRAP: 0.4686 NDCG: 0.6532\n",
      "val Loss: 2.5200 LRAP: 0.6575 NDCG: 0.6842\n",
      "EarlyStopping counter: 3 out of 50\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 1.7655 LRAP: 0.4304 NDCG: 0.6456\n",
      "val Loss: 1.9403 LRAP: 0.5068 NDCG: 0.6565\n",
      "Validation loss decreased (2.082898 --> 1.940255).  Saving model ...\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 1.7374 LRAP: 0.4235 NDCG: 0.6491\n",
      "val Loss: 1.9297 LRAP: 0.4429 NDCG: 0.6562\n",
      "Validation loss decreased (1.940255 --> 1.929694).  Saving model ...\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 1.7210 LRAP: 0.3961 NDCG: 0.6418\n",
      "val Loss: 2.1351 LRAP: 0.4018 NDCG: 0.6444\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 1.7064 LRAP: 0.3902 NDCG: 0.6430\n",
      "val Loss: 1.8392 LRAP: 0.2237 NDCG: 0.6058\n",
      "Validation loss decreased (1.929694 --> 1.839198).  Saving model ...\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 1.7266 LRAP: 0.3716 NDCG: 0.6378\n",
      "val Loss: 1.8175 LRAP: 0.4658 NDCG: 0.6555\n",
      "Validation loss decreased (1.839198 --> 1.817521).  Saving model ...\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 1.7183 LRAP: 0.4020 NDCG: 0.6464\n",
      "val Loss: 1.9136 LRAP: 0.4932 NDCG: 0.6516\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 1.6938 LRAP: 0.4029 NDCG: 0.6392\n",
      "val Loss: 1.7366 LRAP: 0.4612 NDCG: 0.6510\n",
      "Validation loss decreased (1.817521 --> 1.736642).  Saving model ...\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 1.6876 LRAP: 0.4049 NDCG: 0.6435\n",
      "val Loss: 1.8031 LRAP: 0.4886 NDCG: 0.6611\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 1.6883 LRAP: 0.4039 NDCG: 0.6450\n",
      "val Loss: 1.7189 LRAP: 0.4521 NDCG: 0.6521\n",
      "Validation loss decreased (1.736642 --> 1.718867).  Saving model ...\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 1.6971 LRAP: 0.4127 NDCG: 0.6412\n",
      "val Loss: 1.7407 LRAP: 0.4247 NDCG: 0.6414\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 1.6888 LRAP: 0.4216 NDCG: 0.6394\n",
      "val Loss: 1.7203 LRAP: 0.4475 NDCG: 0.6457\n",
      "EarlyStopping counter: 2 out of 50\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 1.6897 LRAP: 0.4637 NDCG: 0.6561\n",
      "val Loss: 1.8021 LRAP: 0.4064 NDCG: 0.6372\n",
      "EarlyStopping counter: 3 out of 50\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 1.6751 LRAP: 0.4382 NDCG: 0.6471\n",
      "val Loss: 1.6934 LRAP: 0.4749 NDCG: 0.6583\n",
      "Validation loss decreased (1.718867 --> 1.693413).  Saving model ...\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 1.6741 LRAP: 0.4441 NDCG: 0.6476\n",
      "val Loss: 1.7441 LRAP: 0.6667 NDCG: 0.7146\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 1.6499 LRAP: 0.4618 NDCG: 0.6584\n",
      "val Loss: 1.7130 LRAP: 0.4247 NDCG: 0.6435\n",
      "EarlyStopping counter: 2 out of 50\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 1.6451 LRAP: 0.4510 NDCG: 0.6523\n",
      "val Loss: 1.7660 LRAP: 0.4292 NDCG: 0.6506\n",
      "EarlyStopping counter: 3 out of 50\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 1.6259 LRAP: 0.4412 NDCG: 0.6519\n",
      "val Loss: 1.6450 LRAP: 0.6073 NDCG: 0.6941\n",
      "Validation loss decreased (1.693413 --> 1.644974).  Saving model ...\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 1.6136 LRAP: 0.4667 NDCG: 0.6588\n",
      "val Loss: 1.8590 LRAP: 0.3927 NDCG: 0.6352\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 1.6047 LRAP: 0.4696 NDCG: 0.6620\n",
      "val Loss: 1.6564 LRAP: 0.5936 NDCG: 0.6963\n",
      "EarlyStopping counter: 2 out of 50\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 1.6031 LRAP: 0.4549 NDCG: 0.6557\n",
      "val Loss: 1.6550 LRAP: 0.6347 NDCG: 0.7069\n",
      "EarlyStopping counter: 3 out of 50\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 1.5799 LRAP: 0.4686 NDCG: 0.6551\n",
      "val Loss: 1.7522 LRAP: 0.3105 NDCG: 0.6183\n",
      "EarlyStopping counter: 4 out of 50\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 1.5825 LRAP: 0.4618 NDCG: 0.6554\n",
      "val Loss: 1.8169 LRAP: 0.6119 NDCG: 0.6964\n",
      "EarlyStopping counter: 5 out of 50\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 1.5776 LRAP: 0.4588 NDCG: 0.6585\n",
      "val Loss: 1.5850 LRAP: 0.4977 NDCG: 0.6733\n",
      "Validation loss decreased (1.644974 --> 1.585045).  Saving model ...\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 1.5640 LRAP: 0.4637 NDCG: 0.6579\n",
      "val Loss: 1.6314 LRAP: 0.4566 NDCG: 0.6557\n",
      "EarlyStopping counter: 1 out of 50\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 1.5480 LRAP: 0.4627 NDCG: 0.6579\n",
      "val Loss: 1.6187 LRAP: 0.4521 NDCG: 0.6468\n",
      "EarlyStopping counter: 2 out of 50\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 1.5522 LRAP: 0.4814 NDCG: 0.6575\n",
      "val Loss: 1.6004 LRAP: 0.4521 NDCG: 0.6468\n",
      "EarlyStopping counter: 3 out of 50\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 1.5468 LRAP: 0.4775 NDCG: 0.6573\n",
      "val Loss: 1.5810 LRAP: 0.4840 NDCG: 0.6566\n",
      "Validation loss decreased (1.585045 --> 1.580958).  Saving model ...\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# model training \n",
    "\n",
    "classes = len(labels[0]) # number of classes in the dataset\n",
    "dataloaders = glycan_loaders\n",
    "\n",
    "\n",
    "model =  prep_infused_sweetnet(\n",
    "            initialization_method = 'external',\n",
    "            num_classes = classes,\n",
    "            embeddings_dict = glm_embeddings, \n",
    "            trainable_embeddings = True\n",
    "            ) \n",
    "\n",
    "optimizer_ft, scheduler, criterion = model_training.training_setup(model, 0.0005, num_classes = classes)\n",
    "\n",
    "model_ft = model_training.train_model(model, dataloaders, criterion, optimizer_ft, scheduler,\n",
    "                   num_epochs = 100, mode = 'multilabel',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sweetnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
